LangChainライブラリを使ってローカルでRAGを動かす方法です。

セキュリティの確保とコストを最小化するために、完全にローカルで無料のLLMモデルと追加データのembedding用のモデルを一度だけダウンロードし、それらを使用してRAGを動かすデモソフトです。

download_model.py: HuggingFaceなどからLLMをダウンロードして、このファイルのあるディレクトリに保存する。
予めhf_modelディレクトリを作成し、embedding用のモデルをダウンロードして、ここに保存しておく
追加データのindexを保存するディレクトリstorageを作成する
追加データ保存用のdataディレクトリを作成し、追加データを保存する（今回は「相撲.txt」という易しくない文章）
index_create.pyを走らせる（追加データを変更したら再度走らせる）
lc_RetrievalQA.py (１つの質問をハードコーディングしたスクリプト）あるいはlc_ConvRetrievalChain.py (質問と答えをチャットできるスクリプト）を走らせる
